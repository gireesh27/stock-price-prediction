{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Single notebook cell: Load from MongoDB (last 5 days), feature engineering, tuning, stacking, save, optional auto-retrain\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from dotenv import load_dotenv\n",
        "from pymongo import MongoClient\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, classification_report, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.options.mode.chained_assignment = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# CONFIG\n",
        "# ---------------------------\n",
        "load_dotenv()  # loads MONGODB_URI etc from .env\n",
        "MONGODB_URI = os.getenv(\"MONGODB_URI\")\n",
        "DB_NAME = os.getenv(\"DB_NAME\", \"stock-price-prediction\")   # match your DB name\n",
        "STOCK_LIST = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\",\n",
        "              \"META\", \"NFLX\", \"NVDA\", \"IBM\", \"ORCL\"]       # your 10 symbols\n",
        "LOOKBACK_DAYS = 30   # last 5 days used for training\n",
        "MODEL_PATH = \"best_stock_model.pkl\"\n",
        "SCALER_PATH = \"scaler.pkl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Helpers\n",
        "# ---------------------------\n",
        "def compute_rsi(series, period=14):\n",
        "    delta = series.diff()\n",
        "    gain = delta.clip(lower=0).rolling(window=period).mean()\n",
        "    loss = -delta.clip(upper=0).rolling(window=period).mean()\n",
        "    rs = gain / (loss.replace(0, 1e-8))\n",
        "    return 100 - (100 / (1 + rs))\n",
        "\n",
        "def connect_mongo(uri):\n",
        "    if not uri:\n",
        "        raise RuntimeError(\"MONGODB_URI not provided in environment\")\n",
        "    client = MongoClient(uri)\n",
        "    return client\n",
        "\n",
        "def load_last_n_days_from_mongo(client, db_name, symbols, days=30):\n",
        "    db = client[db_name]\n",
        "    now_utc = datetime.utcnow()\n",
        "    start = now_utc - timedelta(days=days)\n",
        "    all_frames = []\n",
        "    for sym in symbols:\n",
        "        coll = db[sym.upper()]\n",
        "        cursor = coll.find({\"Date\": {\"$gte\": start}})\n",
        "        df = pd.DataFrame(list(cursor))\n",
        "        if df.empty:\n",
        "            print(f\" No records for {sym} in last {days} days — skipped\")\n",
        "            continue\n",
        "        # Ensure Date column is datetime\n",
        "        if \"_id\" in df.columns and \"Date\" not in df.columns:\n",
        "            df[\"Date\"] = df[\"_id\"]\n",
        "        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "        df = df.sort_values(\"Date\").reset_index(drop=True)\n",
        "        df[\"symbol\"] = sym.upper()\n",
        "        # Keep only expected numeric columns\n",
        "        expected_cols = [\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Adj_Close\", \"symbol\"]\n",
        "        for c in expected_cols:\n",
        "            if c not in df.columns:\n",
        "                df[c] = np.nan\n",
        "        df = df[expected_cols]\n",
        "        all_frames.append(df)\n",
        "        print(f\"Loaded {len(df)} rows for {sym}\")\n",
        "    if not all_frames:\n",
        "        return pd.DataFrame()  # nothing loaded\n",
        "    combined = pd.concat(all_frames, ignore_index=True)\n",
        "    combined = combined.sort_values([\"symbol\",\"Date\"]).reset_index(drop=True)\n",
        "    return combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# UPDATED Feature Engineering (Dynamic indicators)\n",
        "# ---------------------------\n",
        "def add_features(df_all):\n",
        "    df_all = df_all.copy()\n",
        "\n",
        "    def fe_group(g):\n",
        "        g = g.sort_values(\"Date\").reset_index(drop=True)\n",
        "        rows = len(g)\n",
        "\n",
        "        print(f\"[{g['symbol'].iloc[0]}] Rows available = {rows}\")\n",
        "\n",
        "        # ================================\n",
        "        # PRIORITY 1 → FULL INDICATORS\n",
        "        # Need 50 rows (MA50 requires 50)\n",
        "        # ================================\n",
        "        if rows >= 50:\n",
        "            print(\" → Using FULL indicators (RSI14, MA20, MA50)...\")\n",
        "\n",
        "            g[\"RSI14\"] = compute_rsi(g[\"Close\"], 14)\n",
        "            g[\"MA20\"] = g[\"Close\"].rolling(20).mean()\n",
        "            g[\"MA50\"] = g[\"Close\"].rolling(50).mean()\n",
        "\n",
        "            # lag features\n",
        "            g[\"Close_1\"] = g[\"Close\"].shift(1)\n",
        "            g[\"Close_2\"] = g[\"Close\"].shift(2)\n",
        "            g[\"Close_3\"] = g[\"Close\"].shift(3)\n",
        "            g[\"Close_5\"] = g[\"Close\"].shift(5)\n",
        "\n",
        "        # ================================\n",
        "        # PRIORITY 2 → MEDIUM INDICATORS\n",
        "        # Need ≥ 20 rows\n",
        "        # ================================\n",
        "        elif rows >= 20:\n",
        "            print(\" → Using MEDIUM indicators (RSI7, MA10)...\")\n",
        "\n",
        "            g[\"RSI7\"] = compute_rsi(g[\"Close\"], 7)\n",
        "            g[\"MA10\"] = g[\"Close\"].rolling(10).mean()\n",
        "\n",
        "            g[\"Close_1\"] = g[\"Close\"].shift(1)\n",
        "            g[\"Close_2\"] = g[\"Close\"].shift(2)\n",
        "            g[\"Close_3\"] = g[\"Close\"].shift(3)\n",
        "\n",
        "        # ================================\n",
        "        # PRIORITY 3 → SMALL INDICATORS\n",
        "        # Need ≥ 14 rows\n",
        "        # ================================\n",
        "        elif rows >= 14:\n",
        "            print(\" → Using SMALL indicators (RSI7 only + lags)...\")\n",
        "\n",
        "            g[\"RSI7\"] = compute_rsi(g[\"Close\"], 7)\n",
        "\n",
        "            g[\"Close_1\"] = g[\"Close\"].shift(1)\n",
        "            g[\"Close_2\"] = g[\"Close\"].shift(2)\n",
        "\n",
        "        # ================================\n",
        "        # PRIORITY 4 → MINIMAL FEATURES\n",
        "        # Need ≥ 7 rows\n",
        "        # Only lag features\n",
        "        # ================================\n",
        "        elif rows >= 7:\n",
        "            print(\" → Using MINIMAL features (lags only)...\")\n",
        "\n",
        "            g[\"Close_1\"] = g[\"Close\"].shift(1)\n",
        "            g[\"Close_2\"] = g[\"Close\"].shift(2)\n",
        "\n",
        "        # ================================\n",
        "        # PRIORITY 5 → TOO LITTLE DATA\n",
        "        # Skip this stock entirely\n",
        "        # ================================\n",
        "        else:\n",
        "            print(\" - Not enough data (< 7 rows), skipping this symbol\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Target: next candle direction\n",
        "        g[\"target\"] = (g[\"Close\"].shift(-1) > g[\"Close\"]).astype(int)\n",
        "\n",
        "        # Drop unusable rows (indicator warmups)\n",
        "        g = g.dropna().reset_index(drop=True)\n",
        "        return g\n",
        "\n",
        "    # Apply per symbol\n",
        "    df_fe = df_all.groupby(\"symbol\", group_keys=False).apply(fe_group)\n",
        "\n",
        "    print(\"Final feature-engineered shape:\", df_fe.shape)\n",
        "    return df_fe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Training pipeline\n",
        "# ---------------------------\n",
        "def train_and_save_model(df_all, feature_cols=None):\n",
        "    if df_all.empty:\n",
        "        print(\"No data available to train.\")\n",
        "        return None, None\n",
        "\n",
        "    if feature_cols is None:\n",
        "        feature_cols = [\n",
        "            'Open','High','Low','Close','Volume',\n",
        "            'return_1','return_3','return_7',\n",
        "            'sma_5','sma_10','sma_20','ema_10','ema_20',\n",
        "            'vol_5','vol_10','mom_3','mom_7',\n",
        "            'vol_change','vol_ratio_5','rsi_14',\n",
        "            'month','dayofweek','is_quarter_end',\n",
        "            'close_lag_1','close_lag_2','close_lag_3','close_lag_5',\n",
        "            'vol_lag_1','vol_lag_2','vol_lag_3','vol_lag_5'\n",
        "        ]\n",
        "\n",
        "    # ensure all features exist\n",
        "    missing = [c for c in feature_cols if c not in df_all.columns]\n",
        "    if missing:\n",
        "        print(\"Warning - missing features, dropping:\", missing)\n",
        "        feature_cols = [c for c in feature_cols if c in df_all.columns]\n",
        "\n",
        "    X = df_all[feature_cols].copy()\n",
        "    y = df_all[\"target\"].copy()\n",
        "\n",
        "    # sort by time globally, preserve time order for split\n",
        "    df_all = df_all.sort_values(\"Date\").reset_index(drop=True)\n",
        "    split_index = int(len(df_all) * 0.8)\n",
        "    X_train = X.iloc[:split_index]\n",
        "    X_valid = X.iloc[split_index:]\n",
        "    y_train = y.iloc[:split_index]\n",
        "    y_valid = y.iloc[split_index:]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_valid_scaled = scaler.transform(X_valid)\n",
        "\n",
        "    # Models & param grids\n",
        "    models_to_try = {}\n",
        "    param_grids = {}\n",
        "\n",
        "    models_to_try['rf'] = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "    param_grids['rf'] = {\n",
        "        'n_estimators': [200, 400],\n",
        "        'max_depth': [4, 6, 8],\n",
        "        'class_weight': [None, 'balanced']\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        from xgboost import XGBClassifier\n",
        "        models_to_try['xgb'] = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=-1)\n",
        "        param_grids['xgb'] = {\n",
        "            'n_estimators': [100, 200],\n",
        "            'max_depth': [3, 5],\n",
        "            'learning_rate': [0.01, 0.05, 0.1],\n",
        "            'subsample': [0.8, 1.0]\n",
        "        }\n",
        "    except Exception:\n",
        "        print(\"xgboost not available - skipping\")\n",
        "\n",
        "    try:\n",
        "        from lightgbm import LGBMClassifier\n",
        "        models_to_try['lgbm'] = LGBMClassifier(random_state=42, n_jobs=-1)\n",
        "        param_grids['lgbm'] = {\n",
        "            'n_estimators': [100, 200],\n",
        "            'max_depth': [-1, 6],\n",
        "            'learning_rate': [0.01, 0.05, 0.1]\n",
        "        }\n",
        "    except Exception:\n",
        "        print(\"lightgbm not available - skipping\")\n",
        "\n",
        "    print(\"Models available for tuning:\", list(models_to_try.keys()))\n",
        "    tscv = TimeSeriesSplit(n_splits=3)\n",
        "    best_estimators = {}\n",
        "    validation_aucs = {}\n",
        "\n",
        "    for name, model in models_to_try.items():\n",
        "        print(f\"\\nTuning {name} ...\")\n",
        "        grid = RandomizedSearchCV(\n",
        "            estimator=model,\n",
        "            param_distributions=param_grids.get(name, {}),\n",
        "            n_iter=8,\n",
        "            scoring='roc_auc',\n",
        "            cv=tscv,\n",
        "            n_jobs=-1,\n",
        "            random_state=42,\n",
        "            verbose=0\n",
        "        )\n",
        "        grid.fit(X_train_scaled, y_train)\n",
        "        best = grid.best_estimator_\n",
        "        best_estimators[name] = best\n",
        "\n",
        "        if hasattr(best, \"predict_proba\"):\n",
        "            y_valid_proba = best.predict_proba(X_valid_scaled)[:, 1]\n",
        "        else:\n",
        "            try:\n",
        "                y_valid_proba = best.decision_function(X_valid_scaled)\n",
        "                y_valid_proba = (y_valid_proba - y_valid_proba.min()) / (y_valid_proba.max() - y_valid_proba.min() + 1e-8)\n",
        "            except Exception:\n",
        "                y_valid_proba = best.predict(X_valid_scaled)\n",
        "\n",
        "        auc = roc_auc_score(y_valid, y_valid_proba)\n",
        "        validation_aucs[name] = auc\n",
        "        print(f\" Best params ({name}):\", grid.best_params_)\n",
        "        print(f\" Validation AUC ({name}): {auc:.4f}\")\n",
        "\n",
        "    # choose top 3 for stacking\n",
        "    sorted_models = sorted(validation_aucs.items(), key=lambda x: x[1], reverse=True)\n",
        "    print(\"\\nValidation AUCs (sorted):\", sorted_models)\n",
        "    top_k = min(3, len(sorted_models))\n",
        "    top_names = [t[0] for t in sorted_models[:top_k]]\n",
        "    estimators_for_stack = [(name, best_estimators[name]) for name in top_names]\n",
        "\n",
        "    print(\"Stacking models:\", top_names)\n",
        "    final_estimator = LogisticRegression()\n",
        "    stack = StackingClassifier(\n",
        "        estimators=estimators_for_stack,\n",
        "        final_estimator=final_estimator,\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        passthrough=False\n",
        "    )\n",
        "\n",
        "    print(\"\\nTraining final stacking model ...\")\n",
        "    stack.fit(X_train_scaled, y_train)\n",
        "\n",
        "    if hasattr(stack, \"predict_proba\"):\n",
        "        y_valid_proba_stack = stack.predict_proba(X_valid_scaled)[:, 1]\n",
        "    else:\n",
        "        y_valid_proba_stack = stack.predict(X_valid_scaled)\n",
        "\n",
        "    auc_stack = roc_auc_score(y_valid, y_valid_proba_stack)\n",
        "    y_valid_pred = stack.predict(X_valid_scaled)\n",
        "    print(f\"\\nStacking Validation AUC: {auc_stack:.4f}\")\n",
        "    print(\"\\nClassification report (stack):\\n\", classification_report(y_valid, y_valid_pred))\n",
        "\n",
        "    # Confusion matrix display (optional in notebook)\n",
        "    try:\n",
        "        ConfusionMatrixDisplay.from_estimator(stack, X_valid_scaled, y_valid)\n",
        "        plt.title(\"Confusion Matrix - Stacking\")\n",
        "        plt.show()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Save stack and scaler\n",
        "    joblib.dump(stack, MODEL_PATH)\n",
        "    joblib.dump(scaler, SCALER_PATH)\n",
        "    print(f\"\\nSaved: {MODEL_PATH} and {SCALER_PATH}\")\n",
        "\n",
        "    return stack, scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Orchestration: load -> fe -> train\n",
        "# ---------------------------\n",
        "def retrain_from_mongo(days=LOOKBACK_DAYS):\n",
        "    client = connect_mongo(MONGODB_URI)\n",
        "    raw = load_last_n_days_from_mongo(client, DB_NAME, STOCK_LIST, days=days)\n",
        "    if raw.empty:\n",
        "        print(\"No data loaded from MongoDB. Aborting retrain.\")\n",
        "        return None\n",
        "    df_fe = add_features(raw)\n",
        "    print(\"Feature-engineered dataset shape:\", df_fe.shape)\n",
        "    stack, scaler = train_and_save_model(df_fe)\n",
        "    return stack, scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Optional: Background retrain scheduler (every N days)\n",
        "# ---------------------------\n",
        "def start_auto_retrain(every_n_days=30, run_immediately=False):\n",
        "    \"\"\"\n",
        "    Starts a background scheduler that runs retrain_from_mongo every `every_n_days`.\n",
        "    Call this only when you want continuous retraining (not recommended inside shared notebook servers).\n",
        "    \"\"\"\n",
        "    from apscheduler.schedulers.background import BackgroundScheduler\n",
        "    scheduler = BackgroundScheduler()\n",
        "    scheduler.add_job(lambda: retrain_from_mongo(days=LOOKBACK_DAYS), 'interval', days=every_n_days, next_run_time=(datetime.now() if run_immediately else None))\n",
        "    scheduler.start()\n",
        "    print(f\"Auto-retrain scheduled every {every_n_days} days. (BackgroundScheduler started)\")\n",
        "    return scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting retrain job (single run)...\n",
            "Loaded 21 rows for AAPL\n",
            "Loaded 21 rows for MSFT\n",
            "Loaded 21 rows for GOOGL\n",
            "Loaded 21 rows for AMZN\n",
            "Loaded 21 rows for TSLA\n",
            "Loaded 21 rows for META\n",
            "Loaded 21 rows for NFLX\n",
            "Loaded 21 rows for NVDA\n",
            "Loaded 21 rows for IBM\n",
            "Loaded 21 rows for ORCL\n",
            "[AAPL] Rows available = 21\n",
            " → Using MEDIUM indicators (RSI7, MA10)...\n",
            "[AMZN] Rows available = 21\n",
            " → Using MEDIUM indicators (RSI7, MA10)...\n",
            "[GOOGL] Rows available = 21\n",
            " → Using MEDIUM indicators (RSI7, MA10)...\n",
            "[IBM] Rows available = 21\n",
            " → Using MEDIUM indicators (RSI7, MA10)...\n",
            "[META] Rows available = 21\n",
            " → Using MEDIUM indicators (RSI7, MA10)...\n",
            "[MSFT] Rows available = 21\n",
            " → Using MEDIUM indicators (RSI7, MA10)...\n",
            "[NFLX] Rows available = 21\n",
            " → Using MEDIUM indicators (RSI7, MA10)...\n",
            "[NVDA] Rows available = 21\n",
            " → Using MEDIUM indicators (RSI7, MA10)...\n",
            "[ORCL] Rows available = 21\n",
            " → Using MEDIUM indicators (RSI7, MA10)...\n",
            "[TSLA] Rows available = 21\n",
            " → Using MEDIUM indicators (RSI7, MA10)...\n",
            "Final feature-engineered shape: (120, 14)\n",
            "Feature-engineered dataset shape: (120, 14)\n",
            "Warning - missing features, dropping: ['return_1', 'return_3', 'return_7', 'sma_5', 'sma_10', 'sma_20', 'ema_10', 'ema_20', 'vol_5', 'vol_10', 'mom_3', 'mom_7', 'vol_change', 'vol_ratio_5', 'rsi_14', 'month', 'dayofweek', 'is_quarter_end', 'close_lag_1', 'close_lag_2', 'close_lag_3', 'close_lag_5', 'vol_lag_1', 'vol_lag_2', 'vol_lag_3', 'vol_lag_5']\n",
            "Models available for tuning: ['rf', 'xgb', 'lgbm']\n",
            "\n",
            "Tuning rf ...\n",
            " Best params (rf): {'n_estimators': 400, 'max_depth': 8, 'class_weight': 'balanced'}\n",
            " Validation AUC (rf): 0.2786\n",
            "\n",
            "Tuning xgb ...\n",
            " Best params (xgb): {'subsample': 0.8, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.01}\n",
            " Validation AUC (xgb): 0.4321\n",
            "\n",
            "Tuning lgbm ...\n",
            "[LightGBM] [Info] Number of positive: 46, number of negative: 50\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000440 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 151\n",
            "[LightGBM] [Info] Number of data points in the train set: 96, number of used features: 5\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.479167 -> initscore=-0.083382\n",
            "[LightGBM] [Info] Start training from score -0.083382\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            " Best params (lgbm): {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1}\n",
            " Validation AUC (lgbm): 0.5857\n",
            "\n",
            "Validation AUCs (sorted): [('lgbm', 0.5857142857142857), ('xgb', 0.43214285714285716), ('rf', 0.2785714285714286)]\n",
            "Stacking models: ['lgbm', 'xgb', 'rf']\n",
            "\n",
            "Training final stacking model ...\n",
            "\n",
            "Stacking Validation AUC: 0.3000\n",
            "\n",
            "Classification report (stack):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.64      0.56        14\n",
            "           1       0.17      0.10      0.12        10\n",
            "\n",
            "    accuracy                           0.42        24\n",
            "   macro avg       0.33      0.37      0.34        24\n",
            "weighted avg       0.36      0.42      0.38        24\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAAHHCAYAAACbaKDRAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAANhBJREFUeJzt3QucjXX+wPHvmWFmMEbI3bhEyD0qK7tRiVUr6t9NNxGbkqQothWSVNooWdoS3ZSWqGxlUahoZdB2IyINkVKM6+Cc5//6/uqcnXPMcM485/KceT7vXs+a88x5zvM7Z86e7/l+f7/f8/NYlmUJAABwnJRENwAAABSOIA0AgEMRpAEAcCiCNAAADkWQBgDAoQjSAAA4FEEaAACHIkgDAOBQBGkAAByKII2Y27hxo3Tp0kUqVKggHo9H5s+fH9XH//bbb83jzpw5M6qPm8w6depkNvz6WjRv3vyk96tXr57cdNNNcWkTEC6CtEt88803csstt8hpp50mGRkZkpWVJR06dJAnnnhCDh06FNNz9+7dWz777DMZN26cvPjii3LWWWdJSaEf6voFQV/Pwl5H/YKiv9ftsccei/jxv//+exk9erSsW7dOksWRI0fM++rMM880r8spp5wizZo1kz//+c+yfv36wP1WrFhhntuePXsS2l7AyUolugGIvX/9619y5ZVXSnp6utx4440mq9AP0g8//FCGDRsmX3zxhfzjH/+Iybk1cK1cuVLuu+8+uf3222Nyjrp165rzlC5dWhKhVKlScvDgQXnrrbfkqquuCvrdyy+/bL4UHT58uFiPrUF6zJgxJstr3bp12Mf9+9//lkT5v//7P3nnnXekV69e0r9/fzl69KgJzgsWLJBzzz1XmjRpEgjS+tz0i44G8kTbsGGDpKSQt8BZCNIl3JYtW+Saa64xgey9996TGjVqBH43cOBA2bRpkwnisfLjjz+af2P5IaxZqgbCRNEvP1qVeOWVV44L0rNmzZJLLrlE5s6dG5e26JeFsmXLSlpamiTCJ598YoKxVk3+8pe/BP3uqaeecnTWrH9HwGn42ljCPfroo7J//36ZPn16UID2a9iwoQwePDhw+9ixYzJ27Fhp0KCB+dDSDE4/bPPz84OO0/1/+tOfTDZ+zjnnmCCppfQXXnghcB8tZeqXA6UZuwZTPU5p9uT/uSA9Ru9X0KJFi+T3v/+9CfSZmZnSuHHjoABQVJ+0fin5wx/+IOXKlTPH9ujRQ7766qtCz6dfVvwZnfad9+nTxwS8cF177bUmeywYhDRgablbfxfq559/lqFDh0qLFi3Mc9KycLdu3eTTTz8N3Gfp0qVy9tlnm5+1Pf6yuf95+vtac3Jy5LzzzjPB2f+6hPZJa5eD/o1Cn3/Xrl2lYsWKJmOPVreK0i8toVJTU6Vy5cqB113fE6p+/fqB56Z/SzVjxgy54IILpGrVquZ92LRpU5k6dWqh59TXvWPHjlK+fHnzOuprpl+OTlZp0NdLs319zxfWJ62vs7bpo48+krvuukuqVKli3kuXXXZZ4Munn8/nM8+pZs2a5nHPP/98+fLLL+nnhm0E6RJOS7AaPLXMGI5+/frJ/fffL23atJGJEyeaD7/x48ebbDyUBrYrrrhCLrroIvnb3/5mPuz1A0nL5+ryyy83j6H0w1D7oydNmhRR+/Wx9MuAfkl44IEHzHkuvfRS88F5IosXLzYBaNeuXebDUz9ktbyqwcMfCArSDHjfvn3muerP+gGtpdhw6XPVD/TXX389sE8DhZZ29bUMtXnzZjOATp/b448/bgKW9tvr6+0PmGeccYZ5zkr7c/X1000Dst/u3btNcNdSuL62GhwKo33EGmQ0WHu9XrPv6aefNsFq8uTJJrhEg/9LmZb5/cGvqNdL3xNK3yP+56ZtVBqQ9bH0S4f+zbOzs+W2226TKVOmBD2O/p20UqFfekaMGCEPP/yweS3efffdIs+tmb6+h7QL6KWXXjLdFScyaNAg8+Vp1KhRcuutt5r/T4V23ei59f2i4y0mTJggp59+unn/HThwIIxXDTgBXU8aJdPevXt1rXCrR48eYd1/3bp15v79+vUL2j906FCz/7333gvsq1u3rtm3fPnywL5du3ZZ6enp1t133x3Yt2XLFnO/CRMmBD1m7969zWOEGjVqlLm/38SJE83tH3/8sch2+88xY8aMwL7WrVtbVatWtXbv3h3Y9+mnn1opKSnWjTfeeNz5+vbtG/SYl112mVW5cuUiz1nweZQrV878fMUVV1gXXnih+dnr9VrVq1e3xowZU+hrcPjwYXOf0Oehr98DDzwQ2PfJJ58c99z8OnbsaH43bdq0Qn+nW0ELFy4093/wwQetzZs3W5mZmVbPnj2taPL5fIF2VatWzerVq5c1ZcoUa+vWrcfdV18PvZ8+71AHDx48bl/Xrl2t0047LXB7z549Vvny5a127dpZhw4dOq4dftqeZs2amZ/nzp1rlS5d2urfv/9xr7++H/Xv6aevubavc+fOQY83ZMgQKzU11Zxf7dy50ypVqtRxr+Xo0aPN8QUfE4gUmXQJlpeXZ/7VMmA43n77bfOvZp0F3X333ebf0L5rLUFqOdlPsyAtRWuWGC3+vuw33njDlBTDsWPHDjMaWrP6SpUqBfa3bNnSZP3+51nQgAEDgm7r89Is1f8ahkPL2lqi3rlzpym167+FlbqVlnD9g5Q0s9Vz+Uv5a9asCfuc+jhaCg+HToPTEf6anWsmq+VvzaajSasJCxculAcffNBUVrSfXsc+aFZ89dVXh90nXaZMmcDPe/fulZ9++slUGfS9pbf93SBa/Rg+fPhxYxJCu0yUtkXboK+BPu9wB4lpFaPg4+l7Q/9mW7duNbeXLFliqgaa6Ydm4IBdBOkSTPvnlH6QhUM/dPSDS/upC6pevboJlv4PJb86deoc9xj6wfzLL79ItOiHqpaotQxfrVo1U3Z/7bXXThiw/e3UgBdKS8j6gR9ahgx9Lvo8VCTP5eKLLzZfiGbPnm3Kvdo3Gvpa+mn7tcyrZVENtKeeeqr5kvPf//43EITCUatWrYgGiek0MP3iol9innzySdPnezLa/6pfOPybjnE4EX0+Oppf+7+1dK/B8Xe/+535u4U7wl+7Mzp37hwYT6Cvjb+/3f/6+Pu/w5kDrQMor7/+ejPyXMv7hQXxopzsveF/v4X+rfV19t8XKC6CdAkP0trX+Pnnn0d0XLgfYDoQqDCWZRX7HP7+0oIZ1fLly00f8w033GCCmAZuzYhD72uHnedSMDhphvr888/LvHnzisyi1UMPPWQqFtq/rP2imn1qZqjzicOtGIRmnOFYu3at6adX2gceDv2yoYMO/Vsk8731/vrFSv+G+oVEA/WJ+qr9wffCCy80X6a0v14rOPraDBkyxPw+ktenYDt0XIZWUVavXh339wZQXEzBKuF0YJLOgda5yu3btz/hfbUkqR+AOiJZM06/H374wZQp/YOCokEzjMJKn6HZutLsXj+0ddMPbQ1wmqm9//77Jtsq7Hn4572G0vm6mrVqhhYLGpife+450+bCBtv5zZkzxwzy0lH3Belrou3ziyTjOxmtHmhpXLspNGDpyH8dqewfQV4UrQoUvFCLDkSMlM5h1+4GfW9p8NXqTFHPTQdm6UDBN998MyiL1b93QToDQemX0KIqFn5aDtcBYzpi/I9//KMsW7bMfCGKBv/7TQdS6kh1P+3CiGZVCe5EJl3C3XPPPSYgablYg21hWYuO/PWXa1XoCGwNjEpH0UaLfsBq2VIz44J9yZqBFqSjdkP5L+oROi2sYNak99GMtuAXAf0w19HM/ucZCxp4dQqbzgnWQHSi7Cw0E/vnP/8p27dvD9rn/zIRjfnF9957r3z33XfmddG/qU4P0tHeRb2OftrdoF+G/NuJgrQGYT1HKG2/flHUL2f+EdxFPTd/5lrw9dH3ik7LCu1j1+4FHZEferGYwrJcnVqnFQst8Wslxl8ut0u/POoI8dApYvoeAOwiky7hNBjqVCAtEWt2XPCKYzolSQODfx5nq1atzIe2Zt76wakDdVatWmU+1Hv27Fnk9J7i0CxTg4ZmcnfccYeZk6wfco0aNQoaOKWDnLRUql8QNGPRUu3f//53qV27tpk7XRSdBqNTk7R6cPPNN5tMUPsi9YNap2TFimbQf/3rX8OqcOhz08xWs1otPWvGGhoA9e+nfbLTpk0zAUkDW7t27YIytnDoQDZ93XQakX9KmAY9nUs9cuRIk1VHg05V0mqCvvY6wEr7ZfWLh76HtH9avwD6g3Dbtm3Nv1oV0feDZtvdu3c3wVf72fVnHeSlfeDPPPOMCa76Ra5gd4726+sXUK0G6Hn1S4C2Qd9Pes5QWqXwz7vXLxw6z1/79e3QsRJ6rQH/9EDN1LUNOn9bzxfNaghcKOLx4EhKX3/9tZl2Uq9ePSstLc1MXenQoYM1efJkMx3I7+jRo2baUP369c1UlezsbGvEiBFB9/FPV7nkkktOOvWnqClY6t///rfVvHlz057GjRtbL7300nFTsJYsWWKmkNWsWdPcT//VaT36fELPETpNafHixeY5lilTxsrKyrK6d+9uffnll0H38Z8vdIqXf/pNYdODipqCVZSipmDpVLUaNWqY9mk7V65cWejUqTfeeMNq2rSpmeZT8HkWnFoUquDj5OXlmb9XmzZtzN+3IJ1OpNPS9NzR8MMPP1gPP/ywObc+N21zxYoVrQsuuMCaM2fOcfcfO3asVatWLdOGgq/3m2++abVs2dLKyMgw79lHHnnEeu655wr9m+h9zz333MDf+ZxzzrFeeeWVoNci9HXatGmTad8ZZ5wR+NsXNQVLp8EV9P7775v9+q/fsWPHrJEjR5ppd9oOfb5fffWVmcY3YMAA268r3Muj/5PoLwoAUNJoNUoze52OptUCoDjokwYAmwpbAc0/toMlQ2EHfdIAYJPOjddLlOqgRL0ojfZ16/xw7V8v7DrmQLgI0gBgk04v0xHeOgBPr1LnH0ympW7ADvqkAQCIEb3io86g0OmlOjvlzDPPNNNeT3Z9Aj/6pAEAiBGdIqjT/nSVN51qqV0gOv0v9JoIRSGTBgAgRgMK9foGukBQwYtB6TUC9FoC4XSHJHWftF7CUi+QoC8CFwwAgOSjeaKWhHWdgXBXJisOvSqdXsQpGu0NjTd63X7dQul16nWNgdBV2vSa+zq4MNwTJq3c3FxzUQE2NjY2tuTe9PM8Vg4dOmRVr5oalXbqOuyh+/SiSEVp3769uaDO9u3bzUVvXnzxRXPxnkaNGoXV9qTOpP3rJG9dU0+yMuleR8nU6vW+iW4CEDO+w4dl2+gHw173vjg0g965yytbc+pJVvnix4q8fT6p2/Zbyc3NDSwFrArLov20L7pv377m8rN6SVy9LG+vXr0kJycnrHMmdZD2lxw0QNt54QEnSwkplQElUTy6LDPLe8xWXD75LeZkZQUF6RPR6+/rqmu6Cp1Oz9MFgHQthXBXk0vqIA0AQLi8lk+8WqC2cXxx6eI4uunypboaW7iL2hCkAQCu4BPLbHaOj5QGZB1s1rhxY7Pm+LBhw6RJkyZmBbxwUCMGACBGdC30gQMHmsCsSwXrMqkauHVp1nCQSQMAXMFn/rN3fKSuuuoqsxUXQRoA4ApeyzKbnePjjXI3AAAORSYNAHAFXwIGjtlFkAYAuIJPLPEmWZCm3A0AgEORSQMAXMFHuRsAAGfyMrobAABEC5k0AMAVfL9tdo6PN4I0AMAVvDZHd9s5trgI0gAAV/Bav252jo83+qQBAHAoMmkAgCv46JMGAMCZfOIRr3hsHR9vlLsBAHAoMmkAgCv4rF83O8fHG0EaAOAKXpvlbjvHFhflbgAAHIpMGgDgCt4kzKQJ0gAAV/BZHrPZOT7eKHcDAOBQZNIAAFfwUu4GAMCZvJJituIfH38EaQCAK1g2+6T1+HijTxoAAIcikwYAuIKXPmkAAJzJa6WYrfjHS9xR7gYAwKHIpAEAruATj/hs5KY+iX8qTZAGALiCNwn7pCl3AwDgUGTSAABX8NoeOEa5GwCAGPZJe2wdH2+UuwEAcCgyaQCAK/hsXrs7EaO7yaQBAK7qk/ba2CI6n9crI0eOlPr160uZMmWkQYMGMnbsWLEi6NsmkwYAuCaT9sUxk37kkUdk6tSp8vzzz0uzZs1k9erV0qdPH6lQoYLccccdYT0GQRoAgBhYsWKF9OjRQy655BJzu169evLKK6/IqlWrwn4Myt0AAFfwWh7bm8rLywva8vPzCz3fueeeK0uWLJGvv/7a3P7000/lww8/lG7duoXdZjJpAIAreG0OHPP+Vu7Ozs4O2j9q1CgZPXr0cfcfPny4CeJNmjSR1NRU00c9btw4ue6668I+J0EaAIAI5ObmSlZWVuB2enp6ofd77bXX5OWXX5ZZs2aZPul169bJnXfeKTVr1pTevXuHdS6CNADAFXxWitmKf/yvmbQG6IJBuijDhg0z2fQ111xjbrdo0UK2bt0q48ePJ0gDABCLcne4Dh48KCkpwefTsrfP5wv7MQjSAADEQPfu3U0fdJ06dUy5e+3atfL4449L3759w34MgjQAwBV8v43wtnN8JCZPnmwuZnLbbbfJrl27TF/0LbfcIvfff3/Yj0GQBgC4gs/2xUwiO7Z8+fIyadIksxUX86QBAHAoMmkAgCt4ba8nHf+8liANAHAFXxKuJ02QBgC4gjcJM2n6pAEAcCgyaQCAK3htX8yEPmkAAGLCZ3nMZuf4eKPcDQCAQ5FJAwBcwWez3G3nQijFRZAGALiCz/YqWIzuBgAAvyGTBgC4glc8ZrNzfLwRpAEAruCj3A0AAKKFTBoA4ApemyVrPT7eCNIAAFfwJWG5myANAHAFLwtsAACAaCGTBgC4gmVzPWk9Pt4I0gAAV/BS7gYAANFCJg0AcAVfEi5VSZAGALiC1+YqWHaOLS7K3QAAOBSZNADAFXyUuwEAcCafpJjNzvHxRrkbAACHIpMGALiC1/KYzc7x8UaQBgC4go8+aQAAnMmyuQqWHh9v9EkDAOBQZNIAAFfwisdsdo6PN4I0AMAVfJa9fmU9Pt4odwMA4FBk0gjLwf0p8vyjNWTFOxVkz+5S0qDZIbl17DZp3PpQopsG2Fbp3VyptHB70L4jVTPkuxGtE9YmRJ/P5sAxO8cmdSY9ZcoUqVevnmRkZEi7du1k1apViW4SQky8O1vWLM+UeyZvlWlL1kvbjvtk+NUN5acdpRPdNCAq8quXkS1j2gS2bYOaJbpJiDKfeGxvkdC45vF4jtsGDhyYPEF69uzZctddd8moUaNkzZo10qpVK+natavs2rUr0U3Db/IPeeTDt0+Rfn/dIS1+d0Bq1T8iNwzdKTXr5cuCFyonunlAdKR4xJuVFth8mXwBhT2ffPKJ7NixI7AtWrTI7L/yyiuTJ0g//vjj0r9/f+nTp480bdpUpk2bJmXLlpXnnnsu0U3Db7xej/i8HklL9wXtT8/wyRerMhPWLiCaSv90WOqNypG6Y9dKtRc3Sqlf8hPdJMToimN2tkhUqVJFqlevHtgWLFggDRo0kI4dOyZHkD5y5Ijk5ORI586d/9eglBRze+XKlYlsGgoom+mTM9oekFmTqsvunaXE6xVZMreifJVTTn7+gWENSH6H62bKD70ayPe3NJEfr6wvpX7Ol1qTvxDPYW+im4YY9Enb2ezEu5deekn69u1rSt7hSugn7E8//SRer1eqVasWtF9vr1+//rj75+fnm80vLy8vLu2EmL7ox++qI9e2aS4pqZY0bHFQOvX8RTb+t2yimwbYdvCMioGfj9T8NWjXfWCtZK7bLft+VzWhbYPzhMae9PR0s53I/PnzZc+ePXLTTTdFdK6El7sjMX78eKlQoUJgy87OTnSTXKNmvSPy2Oub5I1N/5WXVn8hk9/eKMeOeqRGXUqCKHl8ZUrJ0SoZkvbT4UQ3BVFkBn9ZNrbfBo5p7CkYizQ2ncz06dOlW7duUrNmzYjanNBM+tRTT5XU1FT54Ycfgvbrba3fhxoxYoQZZFbw2wyBOr4yyvrMtm9PquQsy5J+f/0+0U0Cos6T75XSuw/LvqxTE90URJFVjBHaocer3NxcycrKCuw/WRa9detWWbx4sbz++usRnzOhQTotLU3atm0rS5YskZ49e5p9Pp/P3L799tuPu384JQXExuql5cWyRLIb5Mv2LWny7Nhakt3wsHS5eneimwbYVvmNrXKgWUU5VilNSu09KpXe3Sbi8ci+NgTpksQXpVWwNEAXDNInM2PGDKlatapccsklEZ8z4aN+NDPu3bu3nHXWWXLOOefIpEmT5MCBA2a0N5zjQF6qzBhfw8yLLn+KVzpcvEf6DN8hpZilghKg1N4jUv3FjZJ64Jh4M0vLodPKS+6dzZmGBds08dQgrXGuVKlSyRekr776avnxxx/l/vvvl507d0rr1q3l3XffPW4wGRKr46V7zAaURD/ceHqim4ASesWxxYsXy3fffWdGdRdHwoO00tJ2YeVtAACcVu6ORJcuXcTSvsJiSqrR3QAAuIkjMmkAAGLNZ3N0t51ji4sgDQBwhUSUu+2i3A0AgEORSQMAXMGXhJk0QRoA4Aq+JAzSlLsBAHAoMmkAgCv4kjCTJkgDAFzBsjmNqviXJCk+gjQAwBV8SZhJ0ycNAIBDkUkDAFzBl4SZNEEaAOAKviQM0pS7AQBwKDJpAIAr+JIwkyZIAwBcwbI8ZrNzfLxR7gYAwKHIpAEAruBjPWkAAJzJl4R90pS7AQBwKDJpAIArWEk4cIwgDQBwBV8SlrsJ0gAAV7CSMJOmTxoAAIcikwYAuIJls9xNnzQAADFimUBr7/h4o9wNAIBDkUkDAFzBJx7zn53j440gDQBwBYvR3QAAIFrIpAEAruCzPOLhYiYAADiPZdkc3Z2A4d2UuwEAcCgyaQCAK1hJOHCMIA0AcAUrCYM05W4AgKtWwfLZ2CK1fft2uf7666Vy5cpSpkwZadGihaxevTrs48mkAQCIgV9++UU6dOgg559/vrzzzjtSpUoV2bhxo1SsWDHsxyBIAwBcwYrz6O5HHnlEsrOzZcaMGYF99evXj+gxKHcDAFwUpD02tsjO9+abb8pZZ50lV155pVStWlXOPPNMeeaZZyJ6DII0AAARyMvLC9ry8/MLvd/mzZtl6tSpcvrpp8vChQvl1ltvlTvuuEOef/75sM9FkAYAuIJlK4v+38hwLWFXqFAhsI0fP77Q8/l8PmnTpo089NBDJov+85//LP3795dp06aF3Wb6pAEA7llPWuwdr3JzcyUrKyuwPz09vdD716hRQ5o2bRq074wzzpC5c+eGfU6CNAAAEdAAXTBIF0VHdm/YsCFo39dffy1169YN+1wEaQCAK1hxvpjJkCFD5NxzzzXl7quuukpWrVol//jHP8wWLvqkAQDuqndbNrYInH322TJv3jx55ZVXpHnz5jJ27FiZNGmSXHfddWE/Bpk0AMAdLHuZtB4fqT/96U9mKy4yaQAAHIpMGgDgClYSridNkAYAuILFKlgAACBayKQBAO5geYo1+Cvo+DgjSAMAXMFKwj5pyt0AADgUmTQAwB2sKF2822lBWtfEDNell15qpz0AAMSElYSju8MK0j179gzrwTwej3i9XrttAgAA4QZpXRMTAICkZ4l7+qQPHz4sGRkZ0WsNAAAxYiVhuTvi0d1aztaVPGrVqiWZmZmyefNms3/kyJEyffr0WLQRAICkWwUrIUF63LhxMnPmTHn00UclLS0tsF+X4Xr22Wej3T4AAFwr4iD9wgsvmAWrdT3M1NTUwP5WrVrJ+vXro90+AACixBOFzeF90tu3b5eGDRsWOrjs6NGj0WoXAADi9nnSEWfSTZs2lQ8++OC4/XPmzJEzzzwzWu0CAMD1Is6k77//fundu7fJqDV7fv3112XDhg2mDL5gwYLYtBIAALvckEn36NFD3nrrLVm8eLGUK1fOBO2vvvrK7Lvoooti00oAAKK1CpadLRnmSf/hD3+QRYsWRb81AADA/sVMVq9ebTJofz9127Zti/tQAADEnJWES1VGHKS3bdsmvXr1ko8++khOOeUUs2/Pnj1y7rnnyquvviq1a9eORTsBALDHDX3S/fr1M1OtNIv++eefzaY/6yAy/R0AAEhQJr1s2TJZsWKFNG7cOLBPf548ebLpqwYAwJEsm4O/kmHgWHZ2dqEXLdFretesWTNa7QIAIKo81q+bneMdX+6eMGGCDBo0yAwc89OfBw8eLI899li02wcAgGsX2Agrk65YsaJ4PP9L8w8cOCDt2rWTUqV+PfzYsWPm5759+0rPnj1j11oAAFwkrCA9adKk2LcEAIBYskpon7ReBhQAgKRmJd8UrGJfzEQdPnxYjhw5ErQvKyvLbpsAAEBxBo5pf/Ttt98uVatWNdfu1v7qghsAAI5kJd/AsYiD9D333CPvvfeeTJ06VdLT0+XZZ5+VMWPGmOlXuhIWAACOZCVfkI643K2rXWkw7tSpk/Tp08dcwKRhw4ZSt25defnll+W6666LTUsBAHCZiDNpvQzoaaedFuh/1tvq97//vSxfvjz6LQQAwKVLVUYcpDVAb9myxfzcpEkTee211wIZtn/BDQAAnHrFMY+NzfFBWkvcn376qfl5+PDhMmXKFMnIyJAhQ4bIsGHDYtFGAABcKeI+aQ3Gfp07d5b169dLTk6O6Zdu2bJltNsHAEBSzpMePXq0GVhdkC5IpXEzLvOklQ4Y0w0AAARr1qyZLF68OHDbfzntcIV17yeffDLsB7zjjjsiagAAAPHgsbmSVXGGjWlQrl69erHPGVaQnjhxYlgPpotwEKQBACVZXl5e0G29Zohuhdm4caO5joiO3Wrfvr2MHz9e6tSpE90g7R/NDSD+Gg75ONFNAGLmmHVUvkuyBTays7ODdo8aNcr0P4fS1SJnzpxp+qF37Nhh+qf12iKff/65lC9fPj590gAAuGngWG5ubtA6FUVl0d26dQv8rAOrNWjrGC6dunzzzTeHdUqCNAAAEdAAXZzFpPRaIo0aNZJNmzbFbp40AABJyUrstbv3798v33zzjdSoUSPsYwjSAABX8MT5imNDhw6VZcuWybfffisrVqyQyy67TFJTU6VXr15hPwblbgAAYmDbtm0mIO/evVuqVKli1rj4+OOPzc8xDdIffPCBPP300yZtnzNnjtSqVUtefPFFqV+/vmkEAABuv+LYq6++KnZFXO6eO3eudO3aVcqUKSNr166V/Px8s3/v3r3y0EMP2W4QAAAxYSXfetIRB+kHH3xQpk2bJs8884yULl06sL9Dhw6yZs2aaLcPAADXirjcvWHDBjnvvPOO21+hQgXZs2dPtNoFAEBU2V1uMimWqtRrkBY2x+vDDz80a00DAOBIlsf+5vQg3b9/fxk8eLD85z//Mdfq/v777+Xll182Q81vvfXW2LQSAAAX9klHXO4ePny4+Hw+ufDCC+XgwYOm9K2XRNMgPWjQoNi0EgAAF4o4SGv2fN9998mwYcNM2VuvoNK0aVPJzMyMTQsBAHBpn3SxL2aSlpZmgjMAAEnBiu886YQE6fPPP99k00V577337LYJAAAUJ0i3bt066PbRo0dl3bp1Zn3M3r17R7NtAABEj81yd1Jk0hMnTix0vy54rf3TAAA4kpV85e6orYJ1/fXXy3PPPRethwMAwPWitgrWypUrJSMjI1oPBwCAuD2TjjhIX3755UG3LcuSHTt2yOrVq2XkyJHRbBsAAFHjiilYeo3uglJSUqRx48bywAMPSJcuXaLZNgAAXC2iIO31eqVPnz7SokULqVixYuxaBQAAIhs4lpqaarJlVrsCACQdK/mu3R3x6O7mzZvL5s2bY9MaAABi3CftsbE5Pkg/+OCDZjGNBQsWmAFjeXl5QRsAAIhzn7QODLv77rvl4osvNrcvvfTSoMuD6ihvva391gAAOJIlJTNIjxkzRgYMGCDvv/9+bFsEAEAsWCV4nrRmyqpjx46xbA8AACjOFKwTrX4FAICTeUr6xUwaNWp00kD9888/220TAADRV5LL3f5+6dArjgEAAAcE6WuuuUaqVq0ao6YAABA7npJc7qY/GgCQ1KzkK3enRDq6GwAAOCyT9vl8sW0JAACxZCVfJh3xUpUAACQjT0nukwYAIKlZyZdJR7zABgAAiA8yaQCAO1jJl0kTpAEAruBJwj5pyt0AADgUQRoA4K5yt2VjK6aHH37YXBTszjvvjOg4yt0AAFfwJKjc/cknn8jTTz8tLVu2jPhYMmkAAGJk//79ct1118kzzzwjFStWjPh4gjQAwB2s6JS78/Lygrb8/PwiTzlw4EC55JJLpHPnzsVqMkEaAOAOVnSCdHZ2tlm22b+NHz++0NO9+uqrsmbNmiJ/Hw76pAEAiEBubq5kZWUFbqenpxd6n8GDB8uiRYskIyNDiosgDQBwBc9vm53jlQbogkG6MDk5ObJr1y5p06ZNYJ/X65Xly5fLU089ZUrkqampJz0nQRoA4A5W/K44duGFF8pnn30WtK9Pnz7SpEkTuffee8MK0IogDQBwBU8cp2CVL19emjdvHrSvXLlyUrly5eP2nwgDxwAAcCgyaQCAO1iJXWBj6dKlER9DkAYAuIclSYVyNwAADkUmDQBwBU8SLlVJkAYAuIOV2D7p4qDcDQCAQ5FJAwBcwUO5GwAAh7IodwMAgCghkwYAuIKHcjcAAA5lJV+5myANAHAHK/mCNH3SAAA4FJk0AMAVPPRJAwDgUBblbgAAECVk0gAAV/BYltnsHB9vBGkAgDtYlLsBAECUkEkDAFzBw+huAAAcyqLcDQAAooRMGgDgCh7K3QAAOJSVfOVugjQAwBU8SZhJ0ycNAIBDkUkDANzBotwNAIBjeRIQaO2g3A0AgEORSQMA3MGyft3sHB9nBGkAgCt4GN0NAACihUwaAOAOFqO7AQBwJI/v183O8fFGuRsAAIcik0ZYDu5PkecfrSEr3qkge3aXkgbNDsmtY7dJ49aHEt00wLbm7fbLlbf9KKe3OCiVqx+T0X3rycp3KyS6WYi2JCx3JzSTXr58uXTv3l1q1qwpHo9H5s+fn8jm4AQm3p0ta5Znyj2Tt8q0Jeulbcd9MvzqhvLTjtKJbhpgW0ZZn2z+IkOe+kvtRDcFcRjd7bGxRWLq1KnSsmVLycrKMlv79u3lnXfeSZ4gfeDAAWnVqpVMmTIlkc3ASeQf8siHb58i/f66Q1r87oDUqn9Ebhi6U2rWy5cFL1ROdPMA21a/n/VrpYjs2R3zpC0bWwRq164tDz/8sOTk5Mjq1avlggsukB49esgXX3yRHOXubt26mQ3O5vV6xOf1SFp68KiJ9AyffLEqM2HtAgAn00pxQePGjTPZ9ccffyzNmjUreX3S+fn5ZvPLy8tLaHvcomymT85oe0BmTaoudU7/Vk6pckyWzq8oX+WUM9k0ALjpYiZ5IbEnPT3dbCfi9Xrln//8p6kga9m7RI7uHj9+vFSoUCGwZWdnJ7pJrqF90VrpubZNc/lTvVYyf/qp0qnnL+JJqncQAFezorCJmNhTMBZpbCrKZ599JpmZmSaIDxgwQObNmydNmzYNu8lJlUmPGDFC7rrrrsBt/TZDoI6PmvWOyGOvb5LDB1PkwL4UqVztmIy7pa7UqEsmDcBdcnNzzUAwvxNl0Y0bN5Z169bJ3r17Zc6cOdK7d29ZtmxZ2IE6qYJ0OCUFxH4UrG779qRKzrIs6ffX7xPdJACIa7nbP1o7HGlpadKwYUPzc9u2beWTTz6RJ554Qp5++umSF6SROKuXljfl7uwG+bJ9S5o8O7aWZDc8LF2u3p3opgG2ZZT1Ss36RwK3q2cfkdOaHTJfRn/cnpbQtqFkrYLl8/mCxlY5Okjv379fNm3aFLi9ZcsWUxaoVKmS1KlTJ5FNQ4gDeakyY3wNMy+6/Cle6XDxHukzfIeUYpo0SoBGrQ7JhLnfBG4PGPNrhejfsyvK34bwWYTid9HqDCaNZ/v27ZNZs2bJ0qVLZeHChckRpHXe2Pnnnx+47e9v1pr9zJkzE9gyhOp46R6zASXRf1dmStearRLdDJSwpSp37dolN954o+zYscMMMNMLm2iAvuiii5IjSHfq1EmsBCyiDQBwISu+lwWdPn262MUEGgAAHIqBYwAAV/DEudwdDQRpAIA7+KxfNzvHxxlBGgDgDhZLVQIAgCghkwYAuILHZr+yHh9vBGkAgDtYib/iWKQodwMA4FBk0gAAV/AwBQsAAIeyGN0NAACihEwaAOAKHssym53j440gDQBwB99vm53j44xyNwAADkUmDQBwBQ/lbgAAHMpKvtHdBGkAgDtYXHEMAABECZk0AMAVPFxxDAAAh7IodwMAgCghkwYAuILH9+tm5/h4I0gDANzBotwNAACihEwaAOAOFhczAQDAkTxJeFlQyt0AADgUmTQAwB2s5Bs4RpAGALiDZXNNaPqkAQCIDQ990gAAIFrIpAEALpqCZdk7Ps4I0gAAd7CSb+AY5W4AAByKTBoA4A4+Hf1l8/g4I5MGALhqdLfHxhaJ8ePHy9lnny3ly5eXqlWrSs+ePWXDhg0RPQZBGgCAGFi2bJkMHDhQPv74Y1m0aJEcPXpUunTpIgcOHAj7MSh3AwDcwYrvwLF333036PbMmTNNRp2TkyPnnXdeWI9BkAYAuIOV2NHde/fuNf9WqlQp7GMI0gAARCAvLy/odnp6utlOxOfzyZ133ikdOnSQ5s2bh30u+qQBAO7KpC0bm4hkZ2dLhQoVApsOEDsZ7Zv+/PPP5dVXX42oyWTSAAB38EVnClZubq5kZWUFdp8si7799ttlwYIFsnz5cqldu3ZEpyRIAwBcwROlBTY0QBcM0kWxLEsGDRok8+bNk6VLl0r9+vUjPidBGgCAGNAS96xZs+SNN94wc6V37txp9muJvEyZMmE9Bn3SAAB3sKLTJx2uqVOnmhHdnTp1kho1agS22bNnh/0YZNIAAHfwWVqztnd8BLTcbReZNAAADkUmDQBwByv5lqokSAMAXMKyGWhZTxoAAPyGTBoA4A4W5W4AAJzJp0E2fqO7o4FyNwAADkUmDQBwB8v362bn+DgjSAMA3MGiTxoAAGfy0ScNAACihEwaAOAOFuVuAACcybIZaOMfoyl3AwDgVGTSAAB3sCh3AwDgTD6d5+yzeXx8Ue4GAMChyKQBAO5gUe4GAMCZrOQL0pS7AQBwKDJpAIA7+JLvsqAEaQCAK1iWz2x2jo83gjQAwB0sy142TJ80AADwI5MGALiDZbNPmilYAADEiM8n4rHRr5yAPmnK3QAAOBSZNADAHSzK3QAAOJLl84nlSa4pWJS7AQBwKDJpAIA7WJS7AQBwJp8l4kmuIE25GwAAhyKTBgC4g6WZsJ150pS7AQCICctniWWj3G1R7gYAIEYsn/0tAsuXL5fu3btLzZo1xePxyPz58yNuMkEaAIAYOHDggLRq1UqmTJlS7Meg3A0AcAUrzuXubt26mc0OgjQAwB0sLVcn1wIbSR2k/d9q8vbH/4UD4uWYdTTRTQBi5pgcjdugrGN6Lst+W/Py8oL2p6enmy0WkjpI79u3z/xbt823iW4KEEObE90AIC6f5xUqVIjJY6elpUn16tXlw51v236szMxMyc7ODto3atQoGT16tMRCUgdpHTGXm5sr5cuXNyPnEHv6DVLfoPq6Z2VlJbo5QFTx/o4/zaA1QOvneaxkZGTIli1b5MiRI1Fpb2i8iVUWnfRBOiUlRWrXrp3oZriSfoDxIYaSivd3fMUqgw4N1Lolm6QO0gAAONX+/ftl06ZNgduaza9bt04qVaokderUCesxCNIAAMTA6tWr5fzzzw/cvuuuu8y/vXv3lpkzZ4b1GARpRET7XnSQRCz7YIBE4f2NaOrUqZPtUeseKxEXIwUAACfFZUEBAHAogjQAAA5FkAYAwKEI0gAAOBRBGmHT5dbq1atnLgjQrl07WbVqVaKbBERFNNb9BWKBII2wzJ4928zx0+kpa9asMWukdu3aVXbt2pXopgGOWPcXiAWmYCEsmjmfffbZ8tRTT5nbPp/PXON40KBBMnz48EQ3D4gazaTnzZsnPXv2THRTADJpnJxelD4nJ0c6d+4cdN10vb1y5cqEtg0ASjKCNE7qp59+Eq/XK9WqVQvar7d37tyZsHYBQElHkAYAwKEI0jipU089VVJTU+WHH34I2q+3dSF1AEBsEKRxUmlpadK2bVtZsmRJYJ8OHNPb7du3T2jbAKAkYxUshEWnX+nyameddZacc845MmnSJDNtpU+fPoluGuCIdX+BWGAKFsKm068mTJhgBou1bt1annzySTM1C0h2S5cuDVr31y+SdX+BWCBIAwDgUPRJAwDgUARpAAAciiANAIBDEaQBAHAogjQAAA5FkAYAwKEI0gAAOBRBGrDppptuClp7uFOnTnLnnXcm5IIcuhbynj17iryP/n7+/PlhP+bo0aPNhWvs+Pbbb8159QpeACJDkEaJDZwaGHTTa483bNhQHnjgATl27FjMz/3666/L2LFjoxZYAbgX1+5GifXHP/5RZsyYIfn5+fL222/LwIEDpXTp0jJixIjj7nvkyBETzKNBr/cMANFAJo0SKz093SylWbduXbn11lulc+fO8uabbwaVqMeNGyc1a9aUxo0bm/25ubly1VVXySmnnGKCbY8ePUy51s/r9ZrFRvT3lStXlnvuuUdCr6wbWu7WLwn33nuvZGdnmzZpVj99+nTzuP7rRVesWNFk1Nou/ypj48ePl/r160uZMmWkVatWMmfOnKDz6BePRo0amd/r4xRsZ7i0XfoYZcuWldNOO01GjhwpR48ePe5+Tz/9tGm/3k9fn7179wb9/tlnn5UzzjhDMjIypEmTJvL3v/894rYAOB5BGq6hwUwzZj9danPDhg2yaNEiWbBggQlOXbt2lfLly8sHH3wgH330kWRmZpqM3H/c3/72N7PgwnPPPScffvih/PzzzzJv3rwTnvfGG2+UV155xSxI8tVXX5mAp4+rQW/u3LnmPtqOHTt2yBNPPGFua4B+4YUXZNq0afLFF1/IkCFD5Prrr5dly5YFvkxcfvnl0r17d9PX269fPxk+fHjEr4k+V30+X375pTn3M888IxMnTgy6j64O9dprr8lbb70l7777rqxdu1Zuu+22wO9ffvlluf/++80XHn1+Dz30kAn2zz//fMTtARBCF9gASprevXtbPXr0MD/7fD5r0aJFVnp6ujV06NDA76tVq2bl5+cHjnnxxRetxo0bm/v76e/LlCljLVy40NyuUaOG9eijjwZ+f/ToUat27dqBc6mOHTtagwcPNj9v2LBB02xz/sK8//775ve//PJLYN/hw4etsmXLWitWrAi6780332z16tXL/DxixAiradOmQb+/9957j3usUPr7efPmFfn7CRMmWG3btg3cHjVqlJWammpt27YtsO+dd96xUlJSrB07dpjbDRo0sGbNmhX0OGPHjrXat29vft6yZYs579q1a4s8L4DC0SeNEkuzY81YNUPW8vG1115rRiv7tWjRIqgf+tNPPzVZo2aXBR0+fFi++eYbU+LVbLfg8pylSpUya2wXtZicZrmpqanSsWPHsNutbTh48KBcdNFFQfs1mz/zzDPNz5qxhi4T2r59e4nU7NmzTYavz0/XVNaBdVlZWUH30fWUa9WqFXQefT01+9fXSo+9+eabpX///oH76ONUqFAh4vYACEaQRoml/bRTp041gVj7nTWgFlSuXLmg2xqk2rZta8q3oapUqVLsEnuktB3qX//6V1BwVNqnHS0rV66U6667TsaMGWPK/BpUX331VVPSj7StWiYP/dKgX04A2EOQRomlQVgHaYWrTZs2JrOsWrXqcdmkX40aNeQ///mPnHfeeYGMMScnxxxbGM3WNevUvmQduBbKn8nrgDS/pk2bmmD83XffFZmB6yAt/yA4v48//lgisWLFCjOo7r777gvs27p163H303Z8//335ouO/zwpKSlmsF21atXM/s2bN5uADyC6GDgG/EaDzKmnnmpGdOvAsS1btph5zHfccYds27bN3Gfw4MHy8MMPmwuCrF+/3gygOtEc53r16knv3r2lb9++5hj/Y+pALKVBUkd1a2n+xx9/NJmplpCHDh1qBovp4CstJ69Zs0YmT54cGIw1YMAA2bhxowwbNsyUnWfNmmUGgEXi9NNPNwFYs2c9h5a9CxsEpyO29Tlod4C+Lvp66AhvHTmvNBPXgW56/Ndffy2fffaZmfr2+OOPR9QeAMcjSAO/0elFy5cvN32wOnJas1Xta9U+aX9mfffdd8sNN9xggpb2zWpAveyyy074uFpyv+KKK0xA1+lJ2nd74MAB8zstZ2uQ05HZmpXefvvtZr9eDEVHSGvw03boCHMtf+uULKVt1JHhGvh1epaOAtdR1ZG49NJLzRcBPadeVUwzaz1nKK1G6Otx8cUXS5cuXaRly5ZBU6x0ZLlOwdLArJUDzf71C4O/rQCKz6Ojx2wcDwAAYoRMGgAAhyJIAwDgUARpAAAciiANAIBDEaQBAHAogjQAAA5FkAYAwKEI0gAAOBRBGgAAhyJIAwDgUARpAAAciiANAIA40/8DaGnS/kxYSLwAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saved: best_stock_model.pkl and scaler.pkl\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------\n",
        "# Run single retrain now\n",
        "# ---------------------------\n",
        "if __name__ == \"__main__\" or True:\n",
        "    print(\"Starting retrain job (single run)...\")\n",
        "    retrain_from_mongo(days=LOOKBACK_DAYS)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
